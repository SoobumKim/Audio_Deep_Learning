{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "from collections import defaultdict, Counter\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import librosa\n",
    "import random as rn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "pad1d = lambda a,i : a[0:i] if a.shape[0] > i else np.hstack((a, np.zeros(i - a.shape[0])))\n",
    "pad2d = lambda a,i : a[:, 0:i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0], i - a.shape[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        conv1 = nn.Conv2d(1, 32, 2) # 1@20*40 -> 32@19*39\n",
    "        pool1 = nn.MaxPool2d(2,2) # 32@9*19\n",
    "        conv2 = nn.Conv2d(32, 64, 2) # 32@9*19 -> 64@8*18 \n",
    "        conv2_bn = nn.BatchNorm2d(64)\n",
    "        pool2 = nn.MaxPool2d(2,2) # 64@8*18 -> 64@4*9\n",
    "        conv3 = nn.Conv2d(64, 128, 2) # 64@4*9 -> 128@3*8\n",
    "        conv3_bn = nn.BatchNorm2d(128)\n",
    "        pool3 = nn.MaxPool2d(2,2) # 128@3*8 -> 128@1*4\n",
    "        \n",
    "        self.conv_module = nn.Sequential(\n",
    "            conv1,\n",
    "            nn.ReLU(),\n",
    "            pool1,\n",
    "            conv2,\n",
    "            conv2_bn,\n",
    "            nn.ReLU(),\n",
    "            pool2,\n",
    "            conv3,\n",
    "            conv3_bn,\n",
    "            nn.ReLU(),\n",
    "            pool3\n",
    "        )\n",
    "        \n",
    "        fc1 = nn.Linear(128*1*4, 64)\n",
    "        fc1_bn = nn.BatchNorm1d(64)\n",
    "        fc2 = nn.Linear(64, 32)\n",
    "        fc2_bn = nn.BatchNorm1d(32)\n",
    "        fc3 = nn.Linear(32, 10)\n",
    "        \n",
    "        self.fc_module = nn.Sequential(\n",
    "            fc1,\n",
    "            fc1_bn,\n",
    "            nn.ReLU(),\n",
    "            fc2,\n",
    "            fc2_bn,\n",
    "            nn.ReLU(),\n",
    "            fc3\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv_module(x) # @128*254*7\n",
    "        dim = 1\n",
    "        for d in out.size()[1:]:\n",
    "            dim = dim * d\n",
    "        out = out.view(-1, dim)\n",
    "        out = self.fc_module(out)\n",
    "        return F.softmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNNClassifier().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNClassifier(\n",
       "  (conv_module): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU()\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_module): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=32, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.load_state_dict(torch.load(\"G:/2020/KIST/2. code/Python/Audio/Deep Learning/Model_1/cnn.pt\"))\n",
    "cnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import serial\n",
    "ser = serial.Serial(\n",
    "    'COM5',\n",
    "    115200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav, _ = librosa.load(\"C:/Users/ADmin/Desktop/ë‹­/four_2.wav\")\n",
    "\n",
    "mfcc = librosa.feature.mfcc(wav)\n",
    "padded_mfcc = pad2d(mfcc,40)\n",
    "padded_mfcc = torch.cuda.FloatTensor(padded_mfcc)\n",
    "mfcc = padded_mfcc.unsqueeze(0)\n",
    "mfcc = mfcc.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 20, 40])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = cnn(mfcc)\n",
    "pred_label = torch.argmax(pred_label).item()\n",
    "pred = str(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    if ser.readable():\n",
    "        \n",
    "        shape_num = a\n",
    "        ser.write(shape_num.encode())\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_torch",
   "language": "python",
   "name": "new_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
