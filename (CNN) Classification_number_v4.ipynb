{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "from collections import defaultdict, Counter\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import librosa\n",
    "import random as rn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = []\n",
    "Label = []\n",
    "\n",
    "pad1d = lambda a,i : a[0:i] if a.shape[0] > i else np.hstack((a, np.zeros(i - a.shape[0])))\n",
    "pad2d = lambda a,i : a[:, 0:i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0], i - a.shape[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'C:/Users/ADmin/Desktop/train/audio/'\n",
    "num = {'zero/' : 0,'one/' : 1,'two/' : 2,'three/' : 3,'four/' : 4,'five/' : 5,'six/' : 6,'seven/' : 7,'eight/' : 8,'nine/' : 9}\n",
    "\n",
    "for n_folder,n in num.items():\n",
    "    for fname in os.listdir(DATA_DIR + n_folder):\n",
    "        wav, _ = librosa.load(DATA_DIR + n_folder + fname)\n",
    "\n",
    "        Data.append(wav)\n",
    "        Label.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(Data, Label, test_size = 0.2,random_state = 123, shuffle = True, stratify = Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = []\n",
    "train_mfccs = []\n",
    "train_y = []\n",
    "\n",
    "#STFT한것, CNN분석하기 위해 Spectrogram으로 만든 것, MF한것, mel-spectorgram한것\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    wav = X_train[i]\n",
    "    label = y_train[i]\n",
    "\n",
    "    padded_x = pad1d(wav, 30000)\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(wav)\n",
    "    padded_mfcc = pad2d(mfcc,200)\n",
    "\n",
    "    train_X.append(padded_x)\n",
    "    train_mfccs.append(padded_mfcc) \n",
    "    train_y.append(label)\n",
    "\n",
    "valid_X = []\n",
    "valid_mfccs = []\n",
    "valid_y = []\n",
    "\n",
    "for i in range(len(X_valid)):\n",
    "    wav = X_valid[i]\n",
    "    label = y_valid[i]\n",
    "\n",
    "    padded_x = pad1d(wav, 30000)\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(wav)\n",
    "    padded_mfcc = pad2d(mfcc,200)\n",
    "\n",
    "    valid_X.append(padded_x)\n",
    "    valid_mfccs.append(padded_mfcc) \n",
    "    valid_y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X:  torch.Size([19412, 30000])\n",
      "train_mfccs:  torch.Size([19412, 1, 20, 200])\n",
      "train_y:  torch.Size([19412])\n",
      "----------------------------------\n",
      "valid_X:  torch.Size([4854, 30000])\n",
      "valid_mfccs:  torch.Size([4854, 1, 20, 200])\n",
      "valid_y:  torch.Size([4854])\n"
     ]
    }
   ],
   "source": [
    "train_X = torch.cuda.FloatTensor(train_X)\n",
    "train_mfccs = torch.cuda.FloatTensor(train_mfccs)\n",
    "train_y = torch.cuda.LongTensor(train_y)\n",
    "\n",
    "train_mfccs = train_mfccs.unsqueeze(1)\n",
    "\n",
    "valid_X = torch.cuda.FloatTensor(valid_X)\n",
    "valid_mfccs = torch.cuda.FloatTensor(valid_mfccs)\n",
    "valid_y = torch.cuda.LongTensor(valid_y)\n",
    "\n",
    "valid_mfccs = valid_mfccs.unsqueeze(1)\n",
    "\n",
    "print('train_X: ', train_X.shape)\n",
    "print('train_mfccs: ', train_mfccs.shape)\n",
    "print('train_y: ', train_y.shape)\n",
    "print('----------------------------------')\n",
    "print(\"valid_X: \", valid_X.shape)\n",
    "print(\"valid_mfccs: \", valid_mfccs.shape)\n",
    "print(\"valid_y: \", valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_mfccs, train_y)\n",
    "train_data = DataLoader(train_data, batch_size=40, drop_last=False, shuffle=True)\n",
    "\n",
    "valid_data = TensorDataset(valid_mfccs, valid_y)\n",
    "valid_data = DataLoader(valid_data, batch_size=40, drop_last=False, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19412"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        conv1 = nn.Conv2d(1, 32, 2) # 1@20*200 -> 32@19*199\n",
    "        pool1 = nn.MaxPool2d(2,2) # 32@9*99\n",
    "        conv2 = nn.Conv2d(32, 64, 2) # 32@9*99 -> 64@8*98\n",
    "        conv2_bn = nn.BatchNorm2d(64)\n",
    "        pool2 = nn.MaxPool2d(2,2) # 64@8*98 -> 64@4*49\n",
    "        conv3 = nn.Conv2d(64, 128, 2) # 64@4*49 -> 128@3*48\n",
    "        conv3_bn = nn.BatchNorm2d(128)\n",
    "        pool3 = nn.MaxPool2d(2,2) # 128@3*48 -> 128@1*24\n",
    "        \n",
    "        self.conv_module = nn.Sequential(\n",
    "            conv1,\n",
    "            nn.ReLU(),\n",
    "            pool1,\n",
    "            conv2,\n",
    "            conv2_bn,\n",
    "            nn.ReLU(),\n",
    "            pool2,\n",
    "            conv3,\n",
    "            conv3_bn,\n",
    "            nn.ReLU(),\n",
    "            pool3\n",
    "        )\n",
    "        \n",
    "        fc1 = nn.Linear(128*1*24, 64)\n",
    "        fc1_bn = nn.BatchNorm1d(64)\n",
    "        fc2 = nn.Linear(64, 32)\n",
    "        fc2_bn = nn.BatchNorm1d(32)\n",
    "        fc3 = nn.Linear(32, 10)\n",
    "        \n",
    "        self.fc_module = nn.Sequential(\n",
    "            fc1,\n",
    "            fc1_bn,\n",
    "            nn.ReLU(),\n",
    "            fc2,\n",
    "            fc2_bn,\n",
    "            nn.ReLU(),\n",
    "            fc3\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv_module(x) # @128*254*7\n",
    "        dim = 1\n",
    "        for d in out.size()[1:]:\n",
    "            dim = dim * d\n",
    "        out = out.view(-1, dim)\n",
    "        out = self.fc_module(out)\n",
    "        return F.softmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 32, 19, 199]             160\n",
      "              ReLU-2          [-1, 32, 19, 199]               0\n",
      "         MaxPool2d-3            [-1, 32, 9, 99]               0\n",
      "            Conv2d-4            [-1, 64, 8, 98]           8,256\n",
      "       BatchNorm2d-5            [-1, 64, 8, 98]             128\n",
      "              ReLU-6            [-1, 64, 8, 98]               0\n",
      "         MaxPool2d-7            [-1, 64, 4, 49]               0\n",
      "            Conv2d-8           [-1, 128, 3, 48]          32,896\n",
      "       BatchNorm2d-9           [-1, 128, 3, 48]             256\n",
      "             ReLU-10           [-1, 128, 3, 48]               0\n",
      "        MaxPool2d-11           [-1, 128, 1, 24]               0\n",
      "           Linear-12                   [-1, 64]         196,672\n",
      "      BatchNorm1d-13                   [-1, 64]             128\n",
      "             ReLU-14                   [-1, 64]               0\n",
      "           Linear-15                   [-1, 32]           2,080\n",
      "      BatchNorm1d-16                   [-1, 32]              64\n",
      "             ReLU-17                   [-1, 32]               0\n",
      "           Linear-18                   [-1, 10]             330\n",
      "================================================================\n",
      "Total params: 240,970\n",
      "Trainable params: 240,970\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 3.76\n",
      "Params size (MB): 0.92\n",
      "Estimated Total Size (MB): 4.69\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary # from torch.autograd import Variable\n",
    "\n",
    "cnn = CNNClassifier().cuda()\n",
    "input_size = (1, 20, 200)\n",
    "summary(cnn, input_size) #mfcc - input size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/30 | step: 486/486 | trn loss: 0.0482 | val loss: 0.0428\n",
      "epoch: 2/30 | step: 486/486 | trn loss: 0.0405 | val loss: 0.0399\n",
      "epoch: 3/30 | step: 486/486 | trn loss: 0.0391 | val loss: 0.0393\n",
      "epoch: 4/30 | step: 486/486 | trn loss: 0.0387 | val loss: 0.0390\n",
      "epoch: 5/30 | step: 486/486 | trn loss: 0.0384 | val loss: 0.0389\n",
      "epoch: 6/30 | step: 486/486 | trn loss: 0.0381 | val loss: 0.0387\n",
      "epoch: 7/30 | step: 486/486 | trn loss: 0.0380 | val loss: 0.0386\n",
      "epoch: 8/30 | step: 486/486 | trn loss: 0.0379 | val loss: 0.0384\n",
      "epoch: 9/30 | step: 486/486 | trn loss: 0.0378 | val loss: 0.0386\n",
      "epoch: 10/30 | step: 486/486 | trn loss: 0.0377 | val loss: 0.0386\n",
      "epoch: 11/30 | step: 486/486 | trn loss: 0.0377 | val loss: 0.0384\n",
      "epoch: 12/30 | step: 486/486 | trn loss: 0.0376 | val loss: 0.0386\n",
      "epoch: 13/30 | step: 486/486 | trn loss: 0.0375 | val loss: 0.0385\n",
      "epoch: 14/30 | step: 486/486 | trn loss: 0.0375 | val loss: 0.0385\n",
      "epoch: 15/30 | step: 486/486 | trn loss: 0.0374 | val loss: 0.0384\n",
      "epoch: 16/30 | step: 486/486 | trn loss: 0.0374 | val loss: 0.0382\n",
      "epoch: 17/30 | step: 486/486 | trn loss: 0.0374 | val loss: 0.0382\n",
      "epoch: 18/30 | step: 486/486 | trn loss: 0.0373 | val loss: 0.0383\n",
      "epoch: 19/30 | step: 486/486 | trn loss: 0.0373 | val loss: 0.0382\n",
      "epoch: 20/30 | step: 486/486 | trn loss: 0.0372 | val loss: 0.0383\n",
      "epoch: 21/30 | step: 486/486 | trn loss: 0.0372 | val loss: 0.0382\n",
      "epoch: 22/30 | step: 486/486 | trn loss: 0.0372 | val loss: 0.0384\n",
      "epoch: 23/30 | step: 486/486 | trn loss: 0.0371 | val loss: 0.0383\n",
      "epoch: 24/30 | step: 486/486 | trn loss: 0.0372 | val loss: 0.0382\n",
      "epoch: 25/30 | step: 486/486 | trn loss: 0.0371 | val loss: 0.0381\n",
      "epoch: 26/30 | step: 486/486 | trn loss: 0.0371 | val loss: 0.0383\n",
      "epoch: 27/30 | step: 486/486 | trn loss: 0.0371 | val loss: 0.0381\n",
      "epoch: 28/30 | step: 486/486 | trn loss: 0.0371 | val loss: 0.0382\n",
      "epoch: 29/30 | step: 486/486 | trn loss: 0.0371 | val loss: 0.0381\n",
      "epoch: 30/30 | step: 486/486 | trn loss: 0.0371 | val loss: 0.0382\n",
      "Accuracy of the network on the train audio: 95.300330 %\n",
      "Accuracy of the network on the test audio: 93.331960 %\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.0005\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "\n",
    "num_epochs = 30\n",
    "num_batches = len(train_data)\n",
    "\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "train_accuracy = []\n",
    "valid_accuracy = []\n",
    "\n",
    "train_total = 0\n",
    "train_correct = 0\n",
    "train_incorrect = 0\n",
    "valid_total = 0\n",
    "valid_correct = 0\n",
    "valid_incorrect = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    for i, data in enumerate(train_data):\n",
    "        x, label = data\n",
    "\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "            label = label.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        model_output = cnn(x)\n",
    "        loss = criterion(model_output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_data.dataset)\n",
    "        del loss\n",
    "        \n",
    "        for ix in range(len(model_output)):\n",
    "            if torch.argmax(model_output[ix]).item() == label[ix].item():\n",
    "                train_correct += 1\n",
    "            else:\n",
    "                train_incorrect += 1\n",
    "        \n",
    "        if (i+1) % num_batches == 0:\n",
    "            with torch.no_grad():\n",
    "                valid_loss = 0.0\n",
    "                for j, valid in enumerate(valid_data):\n",
    "                    valid_x, valid_label = valid\n",
    "                    if use_cuda:\n",
    "                        valid_x = valid_x.cuda()\n",
    "                        valid_label = valid_label.cuda()\n",
    "                    valid_output = cnn(valid_x)\n",
    "                    v_loss = criterion(valid_output, valid_label)\n",
    "                    valid_loss += v_loss/len(valid_data.dataset)\n",
    "                    \n",
    "                    for idx in range(len(valid_output)):\n",
    "                        if torch.argmax(valid_output[idx]).item() == valid_label[idx].item():\n",
    "                            valid_correct += 1\n",
    "                        else:\n",
    "                            valid_incorrect += 1                  \n",
    "\n",
    "            print(\"epoch: {}/{} | step: {}/{} | trn loss: {:.4f} | val loss: {:.4f}\".format(\n",
    "                epoch+1, num_epochs, i+1, num_batches, train_loss, valid_loss\n",
    "            ))            \n",
    "            \n",
    "            train_loss_list.append(train_loss)\n",
    "            valid_loss_list.append(valid_loss)\n",
    "            train_loss = 0.0\n",
    "    train_accuracy.append((train_correct/(train_correct+train_incorrect))*100)\n",
    "    valid_accuracy.append((valid_correct/(valid_correct+valid_incorrect))*100)\n",
    "\n",
    "print('Accuracy of the network on the train audio: %f %%' % (train_accuracy[-1]))\n",
    "print('Accuracy of the network on the test audio: %f %%' % (valid_accuracy[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x127d3d0d630>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,4)\n",
    "plt.plot(train_accuracy, label = 'Train Loss')\n",
    "plt.plot(valid_accuracy, label = 'Validaton Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn's state_dict:\n",
      "conv_module.0.weight \t torch.Size([32, 1, 2, 2])\n",
      "conv_module.0.bias \t torch.Size([32])\n",
      "conv_module.3.weight \t torch.Size([64, 32, 2, 2])\n",
      "conv_module.3.bias \t torch.Size([64])\n",
      "conv_module.4.weight \t torch.Size([64])\n",
      "conv_module.4.bias \t torch.Size([64])\n",
      "conv_module.4.running_mean \t torch.Size([64])\n",
      "conv_module.4.running_var \t torch.Size([64])\n",
      "conv_module.4.num_batches_tracked \t torch.Size([])\n",
      "conv_module.7.weight \t torch.Size([128, 64, 2, 2])\n",
      "conv_module.7.bias \t torch.Size([128])\n",
      "conv_module.8.weight \t torch.Size([128])\n",
      "conv_module.8.bias \t torch.Size([128])\n",
      "conv_module.8.running_mean \t torch.Size([128])\n",
      "conv_module.8.running_var \t torch.Size([128])\n",
      "conv_module.8.num_batches_tracked \t torch.Size([])\n",
      "fc_module.0.weight \t torch.Size([64, 3072])\n",
      "fc_module.0.bias \t torch.Size([64])\n",
      "fc_module.1.weight \t torch.Size([64])\n",
      "fc_module.1.bias \t torch.Size([64])\n",
      "fc_module.1.running_mean \t torch.Size([64])\n",
      "fc_module.1.running_var \t torch.Size([64])\n",
      "fc_module.1.num_batches_tracked \t torch.Size([])\n",
      "fc_module.3.weight \t torch.Size([32, 64])\n",
      "fc_module.3.bias \t torch.Size([32])\n",
      "fc_module.4.weight \t torch.Size([32])\n",
      "fc_module.4.bias \t torch.Size([32])\n",
      "fc_module.4.running_mean \t torch.Size([32])\n",
      "fc_module.4.running_var \t torch.Size([32])\n",
      "fc_module.4.num_batches_tracked \t torch.Size([])\n",
      "fc_module.6.weight \t torch.Size([10, 32])\n",
      "fc_module.6.bias \t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(\"cnn's state_dict:\")\n",
    "for param_tensor in cnn.state_dict():\n",
    "    print(param_tensor, \"\\t\", cnn.state_dict()[param_tensor].size())\n",
    "    \n",
    "#print(\"Optimizer's state_dict:\")\n",
    "#for var_name in optimizer.cnn_dict():\n",
    "#    print(var_name, \"\\t\", optimizer.cnn_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cnn.state_dict(), 'G:/2020/KIST/2. code/Python/Audio/Deep Learning/Model_1/cnn.pt')\n",
    "#cnn.load_state_dict(torch.load(\"G:\\2020\\KIST\\2. code\\Python\\Audio\\Deep Learning\\Model_1\"))\n",
    "#cnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_torch",
   "language": "python",
   "name": "new_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
