{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "from collections import defaultdict, Counter\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import librosa\n",
    "import random as rn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = []\n",
    "Label = []\n",
    "\n",
    "pad1d = lambda a,i : a[0:i] if a.shape[0] > i else np.hstack((a, np.zeros(i - a.shape[0])))\n",
    "pad2d = lambda a,i : a[:, 0:i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0], i - a.shape[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 지정된 경로를 찾을 수 없습니다: 'C:/Users/ADmin/Desktop/train/audio_small/zero/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-5a85e9df7f9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn_folder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mn_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mwav\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mn_folder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: 'C:/Users/ADmin/Desktop/train/audio_small/zero/'"
     ]
    }
   ],
   "source": [
    "DATA_DIR = 'C:/Users/ADmin/Desktop/train/audio_small/'\n",
    "num = {'zero/' : 0,'one/' : 1,'two/' : 2,'three/' : 3,'four/' : 4,'five/' : 5,'six/' : 6,'seven/' : 7,'eight/' : 8,'nine/' : 9}\n",
    "\n",
    "for n_folder,n in num.items():\n",
    "    for fname in os.listdir(DATA_DIR + n_folder):\n",
    "        wav, _ = librosa.load(DATA_DIR + n_folder + fname)\n",
    "\n",
    "        Data.append(wav)\n",
    "        Label.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(Data, Label, test_size = 0.2,random_state = 123, shuffle = True, stratify = Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = []\n",
    "train_mfccs = []\n",
    "train_y = []\n",
    "\n",
    "#STFT한것, CNN분석하기 위해 Spectrogram으로 만든 것, MF한것, mel-spectorgram한것\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    wav = X_train[i]\n",
    "    label = y_train[i]\n",
    "\n",
    "    padded_x = pad1d(wav, 30000)\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(wav)\n",
    "    padded_mfcc = pad2d(mfcc,40)\n",
    "\n",
    "    train_X.append(padded_x)\n",
    "    train_mfccs.append(padded_mfcc) \n",
    "    train_y.append(label)\n",
    "\n",
    "valid_X = []\n",
    "valid_mfccs = []\n",
    "valid_y = []\n",
    "\n",
    "for i in range(len(X_valid)):\n",
    "    wav = X_valid[i]\n",
    "    label = y_valid[i]\n",
    "\n",
    "    padded_x = pad1d(wav, 30000)\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(wav)\n",
    "    padded_mfcc = pad2d(mfcc,40)\n",
    "\n",
    "    valid_X.append(padded_x)\n",
    "    valid_mfccs.append(padded_mfcc) \n",
    "    valid_y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X:  torch.Size([18932, 30000])\n",
      "train_mfccs:  torch.Size([18932, 1, 20, 40])\n",
      "train_y:  torch.Size([18932])\n",
      "----------------------------------\n",
      "valid_X:  torch.Size([4734, 30000])\n",
      "valid_mfccs:  torch.Size([4734, 1, 20, 40])\n",
      "valid_y:  torch.Size([4734])\n"
     ]
    }
   ],
   "source": [
    "train_X = torch.cuda.FloatTensor(train_X)\n",
    "train_mfccs = torch.cuda.FloatTensor(train_mfccs)\n",
    "train_y = torch.cuda.LongTensor(train_y)\n",
    "\n",
    "train_mfccs = train_mfccs.unsqueeze(1)\n",
    "\n",
    "valid_X = torch.cuda.FloatTensor(valid_X)\n",
    "valid_mfccs = torch.cuda.FloatTensor(valid_mfccs)\n",
    "valid_y = torch.cuda.LongTensor(valid_y)\n",
    "\n",
    "valid_mfccs = valid_mfccs.unsqueeze(1)\n",
    "\n",
    "print('train_X: ', train_X.shape)\n",
    "print('train_mfccs: ', train_mfccs.shape)\n",
    "print('train_y: ', train_y.shape)\n",
    "print('----------------------------------')\n",
    "print(\"valid_X: \", valid_X.shape)\n",
    "print(\"valid_mfccs: \", valid_mfccs.shape)\n",
    "print(\"valid_y: \", valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_mfccs, train_y)\n",
    "train_data = DataLoader(train_data, batch_size=240, drop_last=False, shuffle=True)\n",
    "\n",
    "valid_data = TensorDataset(valid_mfccs, valid_y)\n",
    "valid_data = DataLoader(valid_data, batch_size=60, drop_last=False, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18932"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        conv1 = nn.Conv2d(1, 32, 2) # 1@20*40 -> 32@19*39\n",
    "        pool1 = nn.MaxPool2d(2,2) # 32@9*19\n",
    "        conv2 = nn.Conv2d(32, 64, 2) # 32@9*19 -> 64@8*18 \n",
    "        conv2_bn = nn.BatchNorm2d(64)\n",
    "        pool2 = nn.MaxPool2d(2,2) # 64@8*18 -> 64@4*9\n",
    "        conv3 = nn.Conv2d(64, 128, 2) # 64@4*9 -> 128@3*8\n",
    "        conv3_bn = nn.BatchNorm2d(128)\n",
    "        pool3 = nn.MaxPool2d(2,2) # 128@3*8 -> 128@1*4\n",
    "        \n",
    "        self.conv_module = nn.Sequential(\n",
    "            conv1,\n",
    "            nn.ReLU(),\n",
    "            pool1,\n",
    "            conv2,\n",
    "            conv2_bn,\n",
    "            nn.ReLU(),\n",
    "            pool2,\n",
    "            conv3,\n",
    "            conv3_bn,\n",
    "            nn.ReLU(),\n",
    "            pool3\n",
    "        )\n",
    "        \n",
    "        fc1 = nn.Linear(128*1*4, 64)\n",
    "        fc1_bn = nn.BatchNorm1d(64)\n",
    "        fc2 = nn.Linear(64, 32)\n",
    "        fc2_bn = nn.BatchNorm1d(32)\n",
    "        fc3 = nn.Linear(32, 10)\n",
    "        \n",
    "        self.fc_module = nn.Sequential(\n",
    "            fc1,\n",
    "            fc1_bn,\n",
    "            nn.ReLU(),\n",
    "            fc2,\n",
    "            fc2_bn,\n",
    "            nn.ReLU(),\n",
    "            fc3\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv_module(x) # @128*254*7\n",
    "        dim = 1\n",
    "        for d in out.size()[1:]:\n",
    "            dim = dim * d\n",
    "        out = out.view(-1, dim)\n",
    "        out = self.fc_module(out)\n",
    "        return F.softmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 19, 39]             160\n",
      "              ReLU-2           [-1, 32, 19, 39]               0\n",
      "         MaxPool2d-3            [-1, 32, 9, 19]               0\n",
      "            Conv2d-4            [-1, 64, 8, 18]           8,256\n",
      "       BatchNorm2d-5            [-1, 64, 8, 18]             128\n",
      "              ReLU-6            [-1, 64, 8, 18]               0\n",
      "         MaxPool2d-7             [-1, 64, 4, 9]               0\n",
      "            Conv2d-8            [-1, 128, 3, 8]          32,896\n",
      "       BatchNorm2d-9            [-1, 128, 3, 8]             256\n",
      "             ReLU-10            [-1, 128, 3, 8]               0\n",
      "        MaxPool2d-11            [-1, 128, 1, 4]               0\n",
      "           Linear-12                   [-1, 64]          32,832\n",
      "      BatchNorm1d-13                   [-1, 64]             128\n",
      "             ReLU-14                   [-1, 64]               0\n",
      "           Linear-15                   [-1, 32]           2,080\n",
      "      BatchNorm1d-16                   [-1, 32]              64\n",
      "             ReLU-17                   [-1, 32]               0\n",
      "           Linear-18                   [-1, 10]             330\n",
      "================================================================\n",
      "Total params: 77,130\n",
      "Trainable params: 77,130\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.71\n",
      "Params size (MB): 0.29\n",
      "Estimated Total Size (MB): 1.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary # from torch.autograd import Variable\n",
    "\n",
    "cnn = CNNClassifier().cuda()\n",
    "input_size = (1, 20, 40)\n",
    "summary(cnn, input_size) #mfcc - input size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/100 | step: 79/79 | trn loss: 0.0090 | val loss: 0.0339\n",
      "epoch: 2/100 | step: 79/79 | trn loss: 0.0081 | val loss: 0.0311\n",
      "epoch: 3/100 | step: 79/79 | trn loss: 0.0074 | val loss: 0.0285\n",
      "epoch: 4/100 | step: 79/79 | trn loss: 0.0069 | val loss: 0.0273\n",
      "epoch: 5/100 | step: 79/79 | trn loss: 0.0066 | val loss: 0.0267\n",
      "epoch: 6/100 | step: 79/79 | trn loss: 0.0065 | val loss: 0.0264\n",
      "epoch: 7/100 | step: 79/79 | trn loss: 0.0064 | val loss: 0.0262\n",
      "epoch: 8/100 | step: 79/79 | trn loss: 0.0064 | val loss: 0.0261\n",
      "epoch: 9/100 | step: 79/79 | trn loss: 0.0063 | val loss: 0.0259\n",
      "epoch: 10/100 | step: 79/79 | trn loss: 0.0063 | val loss: 0.0259\n",
      "epoch: 11/100 | step: 79/79 | trn loss: 0.0063 | val loss: 0.0258\n",
      "epoch: 12/100 | step: 79/79 | trn loss: 0.0063 | val loss: 0.0258\n",
      "epoch: 13/100 | step: 79/79 | trn loss: 0.0063 | val loss: 0.0257\n",
      "epoch: 14/100 | step: 79/79 | trn loss: 0.0062 | val loss: 0.0257\n",
      "epoch: 15/100 | step: 79/79 | trn loss: 0.0062 | val loss: 0.0257\n",
      "epoch: 16/100 | step: 79/79 | trn loss: 0.0062 | val loss: 0.0257\n",
      "epoch: 17/100 | step: 79/79 | trn loss: 0.0062 | val loss: 0.0257\n",
      "epoch: 18/100 | step: 79/79 | trn loss: 0.0062 | val loss: 0.0257\n",
      "epoch: 19/100 | step: 79/79 | trn loss: 0.0062 | val loss: 0.0256\n",
      "epoch: 20/100 | step: 79/79 | trn loss: 0.0062 | val loss: 0.0257\n",
      "epoch: 21/100 | step: 79/79 | trn loss: 0.0062 | val loss: 0.0256\n",
      "epoch: 22/100 | step: 79/79 | trn loss: 0.0062 | val loss: 0.0256\n",
      "epoch: 23/100 | step: 79/79 | trn loss: 0.0062 | val loss: 0.0256\n",
      "epoch: 24/100 | step: 79/79 | trn loss: 0.0062 | val loss: 0.0257\n",
      "epoch: 25/100 | step: 79/79 | trn loss: 0.0062 | val loss: 0.0256\n",
      "epoch: 26/100 | step: 79/79 | trn loss: 0.0062 | val loss: 0.0257\n",
      "epoch: 27/100 | step: 79/79 | trn loss: 0.0062 | val loss: 0.0257\n",
      "epoch: 28/100 | step: 79/79 | trn loss: 0.0062 | val loss: 0.0256\n",
      "epoch: 29/100 | step: 79/79 | trn loss: 0.0062 | val loss: 0.0255\n",
      "epoch: 30/100 | step: 79/79 | trn loss: 0.0062 | val loss: 0.0256\n",
      "epoch: 31/100 | step: 79/79 | trn loss: 0.0062 | val loss: 0.0256\n",
      "epoch: 32/100 | step: 79/79 | trn loss: 0.0062 | val loss: 0.0256\n",
      "epoch: 33/100 | step: 79/79 | trn loss: 0.0062 | val loss: 0.0256\n",
      "epoch: 34/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0256\n",
      "epoch: 35/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 36/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 37/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0256\n",
      "epoch: 38/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 39/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0256\n",
      "epoch: 40/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0256\n",
      "epoch: 41/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0256\n",
      "epoch: 42/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0256\n",
      "epoch: 43/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 44/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0256\n",
      "epoch: 45/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 46/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0256\n",
      "epoch: 47/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0256\n",
      "epoch: 48/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 49/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0256\n",
      "epoch: 50/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0256\n",
      "epoch: 51/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0256\n",
      "epoch: 52/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0256\n",
      "epoch: 53/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 54/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0256\n",
      "epoch: 55/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 56/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0256\n",
      "epoch: 57/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 58/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0256\n",
      "epoch: 59/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 60/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 61/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0256\n",
      "epoch: 62/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 63/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0256\n",
      "epoch: 64/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0256\n",
      "epoch: 65/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 66/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 67/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 68/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 69/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 70/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 71/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 72/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0254\n",
      "epoch: 73/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 74/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0256\n",
      "epoch: 75/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 76/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 77/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0256\n",
      "epoch: 78/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 79/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 80/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 81/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0256\n",
      "epoch: 82/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 83/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0256\n",
      "epoch: 84/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 85/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 86/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 87/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0256\n",
      "epoch: 88/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 89/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 90/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 91/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0254\n",
      "epoch: 92/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 93/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 94/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 95/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 96/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 97/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 98/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0255\n",
      "epoch: 99/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0256\n",
      "epoch: 100/100 | step: 79/79 | trn loss: 0.0061 | val loss: 0.0256\n",
      "Accuracy of the network on the train audio: 97.916702 %\n",
      "Accuracy of the network on the test audio: 92.830165 %\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.0005\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "\n",
    "num_epochs = 100\n",
    "num_batches = len(train_data)\n",
    "\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "train_accuracy = []\n",
    "valid_accuracy = []\n",
    "\n",
    "train_total = 0\n",
    "train_correct = 0\n",
    "train_incorrect = 0\n",
    "valid_total = 0\n",
    "valid_correct = 0\n",
    "valid_incorrect = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    for i, data in enumerate(train_data):\n",
    "        x, label = data\n",
    "\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "            label = label.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        model_output = cnn(x)\n",
    "        loss = criterion(model_output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_data.dataset)\n",
    "        del loss\n",
    "        \n",
    "        for ix in range(len(model_output)):\n",
    "            if torch.argmax(model_output[ix]).item() == label[ix].item():\n",
    "                train_correct += 1\n",
    "            else:\n",
    "                train_incorrect += 1\n",
    "        \n",
    "        if (i+1) % num_batches == 0:\n",
    "            with torch.no_grad():\n",
    "                valid_loss = 0.0\n",
    "                for j, valid in enumerate(valid_data):\n",
    "                    valid_x, valid_label = valid\n",
    "                    if use_cuda:\n",
    "                        valid_x = valid_x.cuda()\n",
    "                        valid_label = valid_label.cuda()\n",
    "                    valid_output = cnn(valid_x)\n",
    "                    v_loss = criterion(valid_output, valid_label)\n",
    "                    valid_loss += v_loss/len(valid_data.dataset)\n",
    "                    \n",
    "                    for idx in range(len(valid_output)):\n",
    "                        if torch.argmax(valid_output[idx]).item() == valid_label[idx].item():\n",
    "                            valid_correct += 1\n",
    "                        else:\n",
    "                            valid_incorrect += 1                  \n",
    "\n",
    "            print(\"epoch: {}/{} | step: {}/{} | trn loss: {:.4f} | val loss: {:.4f}\".format(\n",
    "                epoch+1, num_epochs, i+1, num_batches, train_loss, valid_loss\n",
    "            ))            \n",
    "            \n",
    "            train_loss_list.append(train_loss)\n",
    "            valid_loss_list.append(valid_loss)\n",
    "            train_loss = 0.0\n",
    "    train_accuracy.append((train_correct/(train_correct+train_incorrect))*100)\n",
    "    valid_accuracy.append((valid_correct/(valid_correct+valid_incorrect))*100)\n",
    "\n",
    "print('Accuracy of the network on the train audio: %f %%' % (train_accuracy[-1]))\n",
    "print('Accuracy of the network on the test audio: %f %%' % (valid_accuracy[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c109503e48>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,4)\n",
    "plt.plot(train_accuracy, label = 'Train Loss')\n",
    "plt.plot(valid_accuracy, label = 'Validaton Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn's state_dict:\n",
      "conv_module.0.weight \t torch.Size([32, 1, 2, 2])\n",
      "conv_module.0.bias \t torch.Size([32])\n",
      "conv_module.3.weight \t torch.Size([64, 32, 2, 2])\n",
      "conv_module.3.bias \t torch.Size([64])\n",
      "conv_module.4.weight \t torch.Size([64])\n",
      "conv_module.4.bias \t torch.Size([64])\n",
      "conv_module.4.running_mean \t torch.Size([64])\n",
      "conv_module.4.running_var \t torch.Size([64])\n",
      "conv_module.4.num_batches_tracked \t torch.Size([])\n",
      "conv_module.7.weight \t torch.Size([128, 64, 2, 2])\n",
      "conv_module.7.bias \t torch.Size([128])\n",
      "conv_module.8.weight \t torch.Size([128])\n",
      "conv_module.8.bias \t torch.Size([128])\n",
      "conv_module.8.running_mean \t torch.Size([128])\n",
      "conv_module.8.running_var \t torch.Size([128])\n",
      "conv_module.8.num_batches_tracked \t torch.Size([])\n",
      "fc_module.0.weight \t torch.Size([64, 512])\n",
      "fc_module.0.bias \t torch.Size([64])\n",
      "fc_module.1.weight \t torch.Size([64])\n",
      "fc_module.1.bias \t torch.Size([64])\n",
      "fc_module.1.running_mean \t torch.Size([64])\n",
      "fc_module.1.running_var \t torch.Size([64])\n",
      "fc_module.1.num_batches_tracked \t torch.Size([])\n",
      "fc_module.3.weight \t torch.Size([32, 64])\n",
      "fc_module.3.bias \t torch.Size([32])\n",
      "fc_module.4.weight \t torch.Size([32])\n",
      "fc_module.4.bias \t torch.Size([32])\n",
      "fc_module.4.running_mean \t torch.Size([32])\n",
      "fc_module.4.running_var \t torch.Size([32])\n",
      "fc_module.4.num_batches_tracked \t torch.Size([])\n",
      "fc_module.6.weight \t torch.Size([10, 32])\n",
      "fc_module.6.bias \t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(\"cnn's state_dict:\")\n",
    "for param_tensor in cnn.state_dict():\n",
    "    print(param_tensor, \"\\t\", cnn.state_dict()[param_tensor].size())\n",
    "    \n",
    "#print(\"Optimizer's state_dict:\")\n",
    "#for var_name in optimizer.cnn_dict():\n",
    "#    print(var_name, \"\\t\", optimizer.cnn_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cnn.state_dict(), 'G:/2020/KIST/2. code/Python/Audio/Deep Learning/Model_1/cnn.pt')\n",
    "#cnn.load_state_dict(torch.load(\"G:\\2020\\KIST\\2. code\\Python\\Audio\\Deep Learning\\Model_1\"))\n",
    "#cnn.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_torch",
   "language": "python",
   "name": "new_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
